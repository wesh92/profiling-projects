# airflow-values.yaml

executor: CeleryExecutor,KubernetesExecutor

# Security keys (replace these in production)
webserverSecretKey: "a745947747baf7bd0410bd526c88b3f1dc03a6b95cd1700baa992f73ed7f"
fernetKey: "Y1ToX3X8nztBJA56w9z5oCA1YImEn9PcR-vE3FZRIqU="

# Git-sync configuration for private repository
dags:
  persistence:
    enabled: false
  gitSync:
    enabled: true
    # Using SSH URL for private repo
    repo: "git@github.com:wesh92/profiling-projects.git"
    branch: "master"
    # Your DAGs are in this subdirectory
    subPath: "airflow/dags"
    # Reference to the SSH key secret
    sshKeySecret: airflow-git-ssh-secret
    # Wait 60 seconds between syncs
    wait: 60
    # Maximum sync failures before container restarts
    maxFailures: 5
    # Additional git-sync container resources (optional)
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 50m
        memory: 64Mi

images:
  airflow:
    repository: local-airflow
    tag: 1.0.1
    pullPolicy: IfNotPresent

postgresql:
  enabled: false

data:
  metadataSecretName: mydatabase

# Port configurations
ports:
  flowerUI: 5555
  airflowUI: 8085
  workerLogs: 8793
  triggererLogs: 8794
  redisDB: 6379
  statsdIngest: 9125
  statsdScrape: 9102
  pgbouncer: 6543
  pgbouncerScrape: 9127
  apiServer: 8085

service:
  type: ClusterIP
  annotations: {}
  ports:
    - name: airflow-ui
      port: 8085
      targetPort: airflow-ui

# Environment variables
env:
  - name: "AIRFLOW_CONN_KUBERNETES_DEFAULT"
    value: "kubernetes://"
  - name: "AIRFLOW_CONN_KAFKA_DEFAULT"
    value: "kafka:///?bootstrap.servers=my-cluster-kafka-bootstrap.kafka%3A9092&group.id=group_1&security.protocol=PLAINTEXT&auto.offset.reset=beginning"
  # The internal endpoint for your Kafka bootstrap service
  - name: KAFKA_BOOTSTRAP_SERVERS
    value: "my-cluster-kafka-bootstrap.kafka:9092"

  # The topic you want to send messages to
  - name: KAFKA_TOPIC
    value: "performance-metrics"

# API Server configuration
apiServer:
  replicas: 1
  revisionHistoryLimit: ~
  labels: {}
  command: ~
  args:
    [
      "bash",
      "-c",
      "exec airflow api-server --port {{ .Values.ports.apiServer }}",
    ]
  allowPodLogReading: true
  env: []
  serviceAccount:
    automountServiceAccountToken: true
    create: true
    name: ~
    annotations: {}
  service:
    type: ClusterIP
    annotations: {}
    ports:
      - name: api-server
        port: "{{ .Values.ports.apiServer }}"
    loadBalancerIP: ~
    loadBalancerSourceRanges: []
  podDisruptionBudget:
    enabled: false
    config:
      maxUnavailable: 1
  strategy: ~
  securityContexts:
    pod: {}
    container: {}
  containerLifecycleHooks: {}
  waitForMigrations:
    enabled: true
    env: []
    securityContexts:
      container: {}
  extraContainers: []
  extraInitContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  nodeSelector: {}
  affinity: {}
  tolerations: []
  topologySpreadConstraints: []
  priorityClassName: ~
  hostAliases: []
  annotations: {}
  podAnnotations: {}
  networkPolicy:
    ingress:
      from: []
      ports:
        - port: "{{ .Values.ports.apiServer }}"
  resources: {}
  configMapAnnotations: {}
  apiServerConfig: ~
  apiServerConfigConfigMapName: ~
  livenessProbe:
    initialDelaySeconds: 15
    timeoutSeconds: 5
    failureThreshold: 5
    periodSeconds: 10
    scheme: HTTP
  readinessProbe:
    initialDelaySeconds: 15
    timeoutSeconds: 5
    failureThreshold: 5
    periodSeconds: 10
    scheme: HTTP
  startupProbe:
    initialDelaySeconds: 0
    timeoutSeconds: 20
    failureThreshold: 6
    periodSeconds: 10
    scheme: HTTP
